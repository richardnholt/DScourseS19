\documentclass{article}
\usepackage[utf8]{inputenc}

\title{PS8 Holt}
\author{richard.n.holt }
\date{March 2019}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}

Here we go through several different regression tests for the beta variable. The initial created matrix is shown below.

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}} c} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
$1.501$ \\ 
$$-$0.991$ \\ 
$$-$0.247$ \\ 
$0.744$ \\ 
$3.504$ \\ 
$$-$1.999$ \\ 
$0.502$ \\ 
$0.997$ \\ 
$1.256$ \\ 
$1.999$ \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 

Using the OLS estimate, the comparison is accurate with the true values.

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}} cccccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
$1.501$ & $$-$0.991$ & $$-$0.247$ & $0.744$ & $3.504$ & $$-$1.999$ & $0.502$ & $0.997$ & $1.256$ & $1.999$ \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table}

The gradient descent method is also used below.

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}} cccccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
$1.501$ & $$-$0.991$ & $$-$0.247$ & $0.744$ & $3.504$ & $$-$1.999$ & $0.502$ & $0.997$ & $1.256$ & $1.999$ \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 

We can then do the regression estimate with the LBFGS method and the Nelder Mead method. The Nelder Mead is far less accurate than the LBFGS method.

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}} cccccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
$1.462$ & $$-$0.977$ & $$-$0.234$ & $0.775$ & $3.507$ & $$-$1.971$ & $0.537$ & $0.971$ & $1.243$ & $2.002$ \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}} ccccccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
$1.501$ & $$-$0.991$ & $$-$0.247$ & $0.744$ & $3.504$ & $$-$1.999$ & $0.502$ & $0.997$ & $1.256$ & $1.999$ & $$-$0.500$ \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 

The MLE estimate:

\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & y \\ 
\hline \\[-1.8ex] 
 X1 & 1.501$^{***}$ \\ 
  & (0.002) \\ 
  & \\ 
 X2 & $-$0.991$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X3 & $-$0.247$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X4 & 0.744$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X5 & 3.504$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X6 & $-$1.999$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X7 & 0.502$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X8 & 0.997$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X9 & 1.256$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
 X10 & 1.999$^{***}$ \\ 
  & (0.003) \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 100,000 \\ 
R$^{2}$ & 0.971 \\ 
Adjusted R$^{2}$ & 0.971 \\ 
Residual Std. Error & 0.500 (df = 99990) \\ 
F Statistic & 338,240.000$^{***}$ (df = 10; 99990) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}

\end{document}
